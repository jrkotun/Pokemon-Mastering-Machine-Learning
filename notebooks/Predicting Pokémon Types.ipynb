{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Pokemon Types\n",
    "- Encode categorical features that will be used as predictor and response variables.\n",
    "- Try out different models and see which ones have the best accuracy scores out of the box.\n",
    "- Pick one or two of the best performers and tune the models to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent warnings from appearing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the amount of rows shown in printed dataframes\n",
    "pd.set_option('display.max_rows', None, 'display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pokedex csv\n",
    "pokedex = pd.read_csv('../data/pokedex_merged.csv')\n",
    "pokedex = pokedex.where(pd.notnull(pokedex), 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "1. Need to encode both primary and secondary types to use as response variables.\n",
    "2. Need to encode egg groups to use as predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting types and egg groups into one column as a list and adding them as new columns to Pokedex\n",
    "types_list_of_lists = []\n",
    "egg_list_of_lists = []\n",
    "\n",
    "for i in range(0, len(pokedex)):\n",
    "    if pokedex['secondary_type'].iloc[i] == 'None':\n",
    "        type_list = [pokedex['primary_type'].iloc[i]]\n",
    "    else:\n",
    "        type_list = [pokedex['primary_type'].iloc[i], pokedex['secondary_type'].iloc[i]]\n",
    "    types_list_of_lists.append(type_list)\n",
    "    \n",
    "for i in range(0, len(pokedex)):\n",
    "    if pokedex['egg_group_2'].iloc[i] == 'None':\n",
    "        if pokedex['egg_group_1'].iloc[i] == 'None':\n",
    "            egg_list = []\n",
    "        egg_list = [pokedex['egg_group_1'].iloc[i]]\n",
    "    else:\n",
    "        egg_list = [pokedex['egg_group_1'].iloc[i], pokedex['egg_group_2'].iloc[i]]\n",
    "    egg_list_of_lists.append(egg_list)\n",
    "\n",
    "pokedex['type'] = types_list_of_lists\n",
    "pokedex['egg'] = egg_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MultiLabelBinarizer objects and fit them to type and egg columns\n",
    "mlb = MultiLabelBinarizer()\n",
    "type_mlb = mlb.fit_transform(pokedex['type'])\n",
    "\n",
    "mlb2 = MultiLabelBinarizer()\n",
    "egg_mlb = mlb2.fit_transform(pokedex['egg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokedex = pokedex.join(pd.DataFrame(type_mlb, columns=list(mlb.classes_)))\n",
    "pokedex = pokedex.join(pd.DataFrame(egg_mlb, columns=list(mlb2.classes_)), rsuffix='_egg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to Build and Test\n",
    "1. Decision Tree \n",
    "2. K-nearest Neighbors\n",
    "3. Logistic Regression\n",
    "4. Multinomial Naive Bayes\n",
    "5. Neural Network\n",
    "6. Random Forest\n",
    "7. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,mlb_estimator, X_train, y_train, X_test):\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_predictions = clf.predict(X_test)\n",
    "    return clf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Variables for train/test split function\n",
    "tst_size = 0.3\n",
    "seed = 9815\n",
    "\n",
    "# Separate data by response and variable data\n",
    "X = pokedex[list(pokedex.columns)[17:35] + list(pokedex.columns)[56:]]\n",
    "y = pokedex[list(pokedex.columns)[38:56]]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=tst_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate models, fit them with training set, and predict values with the testing set\n",
    "dec_tree_pred = build_model(DecisionTreeClassifier(), LabelPowerset, X_train, y_train, X_test)\n",
    "knn_pred = build_model(KNeighborsClassifier(), LabelPowerset, X_train, y_train, X_test)\n",
    "logreg_pred = build_model(LogisticRegression(), LabelPowerset, X_train, y_train, X_test)\n",
    "multinb_pred = build_model(MultinomialNB(), LabelPowerset, X_train, y_train, X_test)\n",
    "nn_pred = build_model(MLPClassifier(), LabelPowerset, X_train, y_train, X_test)\n",
    "rand_forest_pred = build_model(RandomForestClassifier(), LabelPowerset, X_train, y_train, X_test)\n",
    "svc_pred = build_model(SVC(), LabelPowerset, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score we have achieved using Decision Tree is: 51.7%\n",
      "The F1-score we have achieved using Decision Tree is: 68.85%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using K Nearest Neighbors is: 44.9%\n",
      "The F1-score we have achieved using K Nearest Neighbors is: 70.44%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using Logistic Regression is: 59.52%\n",
      "The F1-score we have achieved using Logistic Regression is: 77.56%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using Multinomial Naive Bayes is: 53.06%\n",
      "The F1-score we have achieved using Multinomial Naive Bayes is: 75.83%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using Neural Network is: 63.61%\n",
      "The F1-score we have achieved using Neural Network is: 80.63%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using Random Forest is: 61.9%\n",
      "The F1-score we have achieved using Random Forest is: 79.12%\n",
      "\n",
      "\n",
      "The accuracy score we have achieved using Support Vector Classification is: 49.32%\n",
      "The F1-score we have achieved using Support Vector Classification is: 72.52%\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score and F1-scores for each model\n",
    "dec_tree_acc = round(accuracy_score(y_test, dec_tree_pred) * 100, 2)\n",
    "dec_tree_f1 = round(f1_score(y_test, dec_tree_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Decision Tree is: ' + str(dec_tree_acc) + '%')\n",
    "print('The F1-score we have achieved using Decision Tree is: ' + str(dec_tree_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "knn_acc = round(accuracy_score(y_test, knn_pred) * 100, 2)\n",
    "knn_f1 = round(f1_score(y_test, knn_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using K Nearest Neighbors is: ' + str(knn_acc) + '%')\n",
    "print('The F1-score we have achieved using K Nearest Neighbors is: ' + str(knn_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "logreg_acc = round(accuracy_score(y_test, logreg_pred) * 100, 2)\n",
    "logreg_f1 = round(f1_score(y_test, logreg_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Logistic Regression is: ' + str(logreg_acc) + '%')\n",
    "print('The F1-score we have achieved using Logistic Regression is: ' + str(logreg_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "multinb_acc = round(accuracy_score(y_test, multinb_pred) * 100, 2)\n",
    "multinb_f1 = round(f1_score(y_test, multinb_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Multinomial Naive Bayes is: ' + str(multinb_acc) + '%')\n",
    "print('The F1-score we have achieved using Multinomial Naive Bayes is: ' + str(multinb_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "nn_acc = round(accuracy_score(y_test, nn_pred) * 100, 2)\n",
    "nn_f1 = round(f1_score(y_test, nn_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Neural Network is: ' + str(nn_acc) + '%')\n",
    "print('The F1-score we have achieved using Neural Network is: ' + str(nn_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "rand_forest_acc = round(accuracy_score(y_test, rand_forest_pred) * 100, 2)\n",
    "rand_forest_f1 = round(f1_score(y_test, rand_forest_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Random Forest is: ' + str(rand_forest_acc) + '%')\n",
    "print('The F1-score we have achieved using Random Forest is: ' + str(rand_forest_f1) + '%')\n",
    "print('\\n')\n",
    "\n",
    "svc_acc = round(accuracy_score(y_test, svc_pred) * 100, 2)\n",
    "svc_f1 = round(f1_score(y_test, svc_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Support Vector Classification is: ' + str(svc_acc) + '%')\n",
    "print('The F1-score we have achieved using Support Vector Classification is: ' + str(svc_f1) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from Different Models\n",
    "#### Conclusion:\n",
    "- Neural Network is consistenly the best performing model in predicting Pokemon's types across multiple seeds. Will tune the hyperparameters of the Neural Network model to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "### Will tune the following hyperparameters for the Neural Network model:\n",
    "- Number of Hidden Layers and Neurons per Layer (hidden_layer_sizes) = Keep hidden layer to one but vary number of neurons to see if we van better fit data and improve accuracy.\n",
    "- Activation Function (activation) = Since this is a non-linear classification, try out different activation functions to manipulate the weights as they are leaving neurons.\n",
    "- Solver = Choose algorithm for weight optimization across nodes.\n",
    "- Learning rate (learning_rate and learning_rate_init) = Stabalize training process by picking a learning rate that helps the network converge to an output. Need something low enough to where it converges to something useful but large enough to where it doesn't take alot of time.\n",
    "- Momentum (momentum) = Control speed of gradient descent. Improve training time while maintaining accuracy.\n",
    "- Number of epochs (max_iter) = Purpose is to increase the number of times the whole training set is shown to the network while training.\n",
    "- Batch size (batch_size) = Control number of minibatches that will be used to train the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (200,), (300,)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
    "    'momentum': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'max_iter': [200, 1000, 5000, 10000], \n",
    "    'batch_size': [32, 64, 128, 256]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier()\n",
    "\n",
    "nn_random = RandomizedSearchCV(estimator=nn, \n",
    "                               param_distributions=param_grid, \n",
    "                               n_iter=50, \n",
    "                               cv=3, \n",
    "                               verbose=2, \n",
    "                               random_state=seed, \n",
    "                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 21.5min finished\n"
     ]
    }
   ],
   "source": [
    "LabelPowerset(nn_random).fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'momentum': 0.8,\n",
       " 'max_iter': 200,\n",
       " 'learning_rate_init': 0.0003,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (200,),\n",
       " 'batch_size': 32,\n",
       " 'activation': 'logistic'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score we have achieved using Neural Network is: 62.59%\n",
      "The F1-score we have achieved using Neural Network is: 80.51%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_pred = build_model(MLPClassifier(**nn_random.best_params_), LabelPowerset, X_train, y_train, X_test)\n",
    "nn_acc = round(accuracy_score(y_test, nn_pred) * 100, 2)\n",
    "nn_f1 = round(f1_score(y_test, nn_pred, average='macro') * 100, 2)\n",
    "print('The accuracy score we have achieved using Neural Network is: ' + str(nn_acc) + '%')\n",
    "print('The F1-score we have achieved using Neural Network is: ' + str(nn_f1) + '%')\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
